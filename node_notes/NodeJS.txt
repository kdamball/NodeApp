Querying & File Reading:
  Streaming API with files as if they were network streams. You cant read/write from a specific point however. For that
  you use filesystem itself. 
  
  Normalizing Path:
    normalizing path from users or as a result of joining two paths. Useful usually before storing files
    eg: var path = require('path');
        path.normalize('/foo/bar//baz/asdf/quux/..');   // => '/foo/bar/baz/asdf'
  
  Joining Paths:
    Using "path.join()"
    eg: var path = require('path');
        path.join('/foo', 'bar', 'baz/asdf', 'quux', '..');  // => '/foo/bar/baz/asdf'
  
  Resolving Paths:
    Resolve a series of paths into a normalized absolute path using "path.resolve()"
    
  Opening a file:
    "fs.open()"
    
  Read a file:
    "fs.read()" See test.js for more details
    
  Writing to file:
    "fs.write()" See test.js for more details
  
  Closing files:
    "fs.close()" Useful for closing files to avoid leaking file descriptors
    
    
External Processes:
  Child processes are designed to avoid interrupting the event loop. 
  General command:  
    exec('Command To Run', options, function(err, stdout, stderr) {
     // ...
    });
    whereby "options" can be
      cwd - Current working directory
      encoding - utf8, ascii etc
      timeout - in milliseconds
      maxBuffer - max byte size for stdout or stderr (default is 200 * 1024)
      killSignal - signal to send when maxBuffer or timeout is reached
      env - environment vars to pass to child process (see example in code)
  You can create a new child process by using "spawn()". You dont have to use "process.execPath" in this
    case like in "exec()" because "spawn()" ignores PATHEXT in windows. Unlike "exec()", you can 
    communicate with the child process. It also isn't a memory hugger! Check sample code for details.
  
Streams:
  Data transfer abstracted as streams. Can be of any type (e.g TCP, file etc)
  Slow client problem: Can be solved by constantly checking on whether there's buffered data.
    require('http').createServer(function(req, res) {
      var rs = fs.createReadStream('/path/to/big/file');

      rs.on('data', function(data) {
        if (!res.write(data)) { //checking to see whether there's slow buffered data
          rs.pause();
        }
      });
      res.on('drain', function() {
        rs.resume();
      });
      rs.on('end', function() {
        res.end();
      });
    }).listen(8080);
  Because this solution is a recurring pattern, Node has this captured to "stream.pipe()"
    require('http').createServer(function(req, res) {
     var rs = fs.createReadStream('/path/to/big/file');
     rs.pipe(res);
    }).listen(8080);

TCP Servers:
  Built by "require('net')" module. 
  "require('net').createServer(function(socket){})" with the socket object representing a connection with a client.
  "socket" object has to be passed into a callback.
  More code in "test.js"

HTTP Servers:
  Uses TCP as its transport protocol.
  Requests:
    When you receive a request you don't grab its body because it hasn't arrived yet. request object is a ReadStream.
    Properties of a request: url, methods, headers
  Response:
    Header - "res.WriteHeader(status, headers)". headers argument is optional.
      You can only change a header (i.e "res.setHeader(name, value)") iff you haven't sent a body ("res.write()") or
        written a header ("res.writeHeader()") because they've already been sent.
      You can also remove it by "res.removeHeader(name)"
    Body - either strings or buffers.
    Streaming HTTP Chunked responses - node allows sending continous data to the client (unless Content-Length is specified)
      Piping a file - using chunked responses, one can easily pipe files (e.g audio & video). Check code
      Piping a child process - Uses the same logic. Remember to kill child process should the response end.

TCP Client:
  TCP is a connection oriented protocol. One endpoint connecting to another and both can send & receive messages.
  TCP ONLY guarantees that the data you send & receive is in order. There are two streams for data, sending (writeable) 
    & receiving(readable). Note that there's no way acknowledge the other side has received the data; just that they 
    have been received in order. 
  Connecting to a TCP Server:
    "require('net').createConnection(port, host)"
    If host argument isn't provided, it defaults to localhost.
    You can also pass a call back as a third option and use it to determine when a connection is established
      "require('net').createConnection(port, host, function(conn){console.log('Connected')})"
    You can also listen to the 'connect' event emitted by the "createConnection()" object
  Sending & Receiving Data:
    "net.createConnection()" returns an instance of the "net.Socket", representing the connection to the server &
      is both a readable & writeable stream
      "
        var conn = net.createConnection(port, host, callback)
        conn.write('Some words to the server from client');
        conn.write('SGVsbG8gV29ybGQh', 'base64') //string with encoding
        conn.write((new Buffer('hello world'))) //raw buffer
        conn.write('Hey', function(){console.log('We wrote to the server')}) //passing a callback function
          //note that the callback is invoked if te data is written to the stream and not received by the server
        conn.on('data', function(data){console.log('We received' +data)}) //listening to data from server
        conn.setEncoding('base64') //if encoding not specified, it'll be treated as buffer
        conn.end() //ending the connection
        conn.end('Bye! Bye!', 'utf-8') //send data when ending
      "
  Errors:
    Errors can happen b'se of hostname not found on DNS, target host isn't reachable, conn. is rejected

HTTP Requests:
  Request - "http.get(option, callback)". "http.get" is shortcut for http.request
    where by options = host, port, path, headers, method etc.
      callback = passes the response object as an argument.
  "http.request()" returns an "http.ClientRequest" object, which is a writeable stream.
  Response Object - "res.statusCode, res.httpVersion, res.headers"
  Pooling Sockets using HTTP.AGENT - For http requests, node uses an agent. Agent is the entity in node making
    http requests for you. It maintains a pool of live TCP sockets (pool of open but out-of-use network
    connections & port pair). When a request happens, the agent will ask to keep the conn. alive. When done,
    the socket is closed. This way you don't have to manually close the HTTP client. When making a request, a socket
    is selected or a new conn. is created for the request, "http.ClientRequest" emits a "socket" event. After 
    request is done, sockets are removed from agent's pool when the socket emits a "close" event or an "agentRemove" 
    event. If you want to keep a request open for a long time, you can remove it from the pool. 
    "
      req.on('socket', function(socket) {
       socket.emit('agentRemove');
      });
    "
    Node allows a max of 5 open sockets/host pair on a given process. This implies, under heavy load, node will 
    serialize requests to the same host-port to re-use the sockets. You can remove this behaviour by disabling 
    agent socket pooling ("agent: false" in "http.request" options). You can also change the max number of open 
    sockets allowed "http.Agent.defaultMaxSockets".
  Request Module - authored by Mikeal Rogers. Abstracts away most of the cumbersome requests actions. 
    "
      var request = require("requests");
      request("http://google.com/search?q=hello+world", function(err, res, body){
        //callback actions
      });
    "
    You can use the "options" object inplace of the url. 
    Redirects: Request module follows redirects by default. You can disable this by setting the "followRedirect" to 
      "false" in request options. Sometimes redirects can be faulty (e.g redirect loops). You can set a max no. for 
      redirects in the "maxRedirects" option.
    You can also perform other HTTP methods like put, post, delete etc. 
      "
        var request = require("request");
        request.post(options, callback);      
      "
    Cookie Jar: By default, request inteprets all cookies in a global cookie jar. You can disable cookies for an app 
      globally by: "request.defaults({jar: false})"
      You can also turn it off on a request basis: 
        "
          var options = {url: "http://example.com", jar: false};
          request(options, callback)
        "
      You can also have a specific jar for each request:
        "
          var jar = request.jar(), option = {url: "http://example.com", jar: jar};
          request(options, callback);
        "

Debugging:
  Console.log - it takes an argument and passes it to "util.format", which spits it backout the usual "stdout".
    Placeholders: %j - JSON encode, %d - number, %s - string
    console.log is a blocking operation (blocks the event loop). Avoid using it in prod. code
  V8 Debugger - Built in node debugger. To run it, "> node debug app.js"
    You can check out the commands with "help"
  Using Node Inspector - Install with "npm install node-inspector"
    Uses the browser (i.e Chrome) for GUI. To use: "> node --debug-brk app.js". "--debug-brk" breaks the app on the 1st
      link while "--debug" enables simply debugging. When debugging servers, use "--debug" and use "--debug-brk" for 
      scripts.
      
Controlling the Callback Flow:
  With Async operations, the result is passed to a callback. With lots of I/O operations, callback mgmt can be tricky.
  Boomerang Effect - It happens when each callback relies on the preceding one finishing first. This leads to several 
    nested callbacks (aka. callback hell).
  Avoiding Boomerang effect by declaring fns - declare all fns in the same scope. You can also use generic flow control 
    mechanism. This includes passing two args:  an array of all callbacks and a final callback or error handling fn.
    (See test.js for more details)
  Using Async Library - Helps with generic flow ctrl mechanism. Check test.js for more code. 
    Series - "async.series" takes an array of fns (to execute one after the previous is done) and fn to call when all 
      fns are done.
    Parallel execution - "async.parallel", just like above, but we execute all fns simultaneously. 
    Cascading - "async.waterfall" for when one fn relies on the previous fn's output.
    Queuing - "async.queue" for performing repetitive async jobs and to control concurrency (no. of pending jobs)
      The results are shown in the order in which they were completed and not how they were previously arranged.
      To ensure order, use "async.forEach"
      Max concurrency settings can be changed afterwards. This can easily be modified to match the obeserved latency,
        or limit the number of requests to a server (i.e: "queue.concurrency"). 
      When a queue's concurrency is maxed, it emits an event. You can check for it using:
        "
          queue.saturated = function(){
            console.log('The queue is full')
          }
        "
      Likewise, you can also listen to the "empty" event or the "drain" event.
    Iterating - built-in array's "forEach" wont work 
      
      

    
    
    




















