Querying & File Reading:
  Streaming API with files as if they were network streams. You cant read/write from a specific point however. For that
  you use filesystem itself. 
  
  Normalizing Path:
    normalizing path from users or as a result of joining two paths. Useful usually before storing files
    eg: var path = require('path');
        path.normalize('/foo/bar//baz/asdf/quux/..');   // => '/foo/bar/baz/asdf'
  
  Joining Paths:
    Using "path.join()"
    eg: var path = require('path');
        path.join('/foo', 'bar', 'baz/asdf', 'quux', '..');  // => '/foo/bar/baz/asdf'
  
  Resolving Paths:
    Resolve a series of paths into a normalized absolute path using "path.resolve()"
    
  Opening a file:
    "fs.open()"
    
  Read a file:
    "fs.read()" See test.js for more details
    
  Writing to file:
    "fs.write()" See test.js for more details
  
  Closing files:
    "fs.close()" Useful for closing files to avoid leaking file descriptors
    
    
External Processes:
  Child processes are designed to avoid interrupting the event loop. 
  General command:  
    exec('Command To Run', options, function(err, stdout, stderr) {
     // ...
    });
    whereby "options" can be
      cwd - Current working directory
      encoding - utf8, ascii etc
      timeout - in milliseconds
      maxBuffer - max byte size for stdout or stderr (default is 200 * 1024)
      killSignal - signal to send when maxBuffer or timeout is reached
      env - environment vars to pass to child process (see example in code)
  You can create a new child process by using "spawn()". You dont have to use "process.execPath" in this
    case like in "exec()" because "spawn()" ignores PATHEXT in windows. Unlike "exec()", you can 
    communicate with the child process. It also isn't a memory hugger! Check sample code for details.
  
Streams:
  Data transfer abstracted as streams. Can be of any type (e.g TCP, file etc)
  Slow client problem: Can be solved by constantly checking on whether there's buffered data.
    require('http').createServer(function(req, res) {
      var rs = fs.createReadStream('/path/to/big/file');

      rs.on('data', function(data) {
        if (!res.write(data)) { //checking to see whether there's slow buffered data
          rs.pause();
        }
      });
      res.on('drain', function() {
        rs.resume();
      });
      rs.on('end', function() {
        res.end();
      });
    }).listen(8080);
  Because this solution is a recurring pattern, Node has this captured to "stream.pipe()"
    require('http').createServer(function(req, res) {
     var rs = fs.createReadStream('/path/to/big/file');
     rs.pipe(res);
    }).listen(8080);

TCP Servers:
  Built by "require('net')" module. 
  "require('net').createServer(function(socket){})" with the socket object representing a connection with a client.
  "socket" object has to be passed into a callback.
  More code in "test.js"

HTTP Servers:
  Uses TCP as its transport protocol.
  Requests:
    When you receive a request you don't grab its body because it hasn't arrived yet. request object is a ReadStream.
    Properties of a request: url, methods, headers
  Response:
    Header - "res.WriteHeader(status, headers)". headers argument is optional.
      You can only change a header (i.e "res.setHeader(name, value)") iff you haven't sent a body ("res.write()") or
        written a header ("res.writeHeader()") because they've already been sent.
      You can also remove it by "res.removeHeader(name)"
    Body - either strings or buffers.
    Streaming HTTP Chunked responses - node allows sending continous data to the client (unless Content-Length is specified)
      Piping a file - using chunked responses, one can easily pipe files (e.g audio & video). Check code
      Piping a child process - Uses the same logic. Remember to kill child process should the response end.
  
    
  















